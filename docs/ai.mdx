---
title: AI
docs:
  - route: https://pro.platejs.org/docs/examples/ai
    title: AI
---

<ComponentPreview name="ai-demo" />

<PackageInfo>

## Features

- Combobox menu with predefined commands:
  - Generate: continue writing, add summary, explain
  - Edit: improve writing, emojify, make it longer or shorter, fix spelling & grammar, simplify language
- Three trigger modes:
  - Cursor mode: trigger at block end
  - Selection mode: trigger with selected text
  - Block selection mode: trigger with selected blocks
- Streaming responses in preview or direct editor insertion
- Markdown support
- Built-in support for Vercel AI SDK chat API

</PackageInfo>

## Installation

```bash
npm install @udecode/plate-ai @udecode/plate-selection @udecode/plate-markdown @udecode/plate-basic-nodes
```

## Usage

### Plugins

<ComponentSource name="ai-kit" />

- [AIMenu](/docs/components/ai-menu)

### AI SDK

This plugin is depending on the [ai](https://npmjs.com/package/ai) package:

- Setup a [route handler](https://sdk.vercel.ai/docs/installation/nextjs-app-router#create-a-route-handler) using [streamText](https://sdk.vercel.ai/docs/ai-sdk-core/generating-text#streamtext).
- Wire up [useChat](https://sdk.vercel.ai/docs/reference/ai-sdk-ui/use-chat) in your [AI menu](/docs/components/ai-menu) component.


### Convert the chunk into plate nodes

By default, AI responses are streamed to the Plate editor in a chunk-by-chunk manner.

However, this chunking approach can cause issues when handling complex nodes like tables and code blocks. If chunks are split too frequently, it can lead to performance problems as these heavy nodes are repeatedly replaced.

To solve this issue, it's recommended to use the `experimental_transform` parameter with the `smoothStream` function in the `streamText` function to optimize the chunk transmission.

The chunking function below implements the following default behavior: it uses line-based chunking for tables, math, links, and code blocks, while using word-based chunking for all other content.

```ts
    const result = streamText({
      experimental_transform: smoothStream({
        chunking: (buffer) => {
          // Check for code block markers
          if (/```[^\s]+/.test(buffer)) {
            isInCodeBlock = true
          }else if(isInCodeBlock && buffer.includes('```') ) {
            isInCodeBlock = false
          }
          // test case: should not deserialize link with markdown syntax
          if (buffer.includes('http')) {
            isInLink = true;
          } else if (buffer.includes('https')) {
            isInLink = true;
          } else if (buffer.includes('\n') && isInLink) {
            isInLink = false;
          }
          if (buffer.includes('*') || buffer.includes('-')) {
            isInList = true;
          } else if (buffer.includes('\n') && isInList) {
            isInList = false;
          }
          // Simple table detection: enter on |, exit on double newline
          if (!isInTable && buffer.includes('|')) {
            isInTable = true;
          } else if (isInTable && buffer.includes('\n\n')) {
            isInTable = false;
          }

          // Use line chunking for code blocks and tables, word chunking otherwise
          // Choose the appropriate chunking strategy based on content type
          let match;

          if (isInCodeBlock || isInTable || isInLink) {
            // Use line chunking for code blocks and tables
            match = CHUNKING_REGEXPS.line.exec(buffer);
          } else if (isInList) {
            // Use list chunking for lists
            match = CHUNKING_REGEXPS.list.exec(buffer);
          } else {
            // Use word chunking for regular text
            match = CHUNKING_REGEXPS.word.exec(buffer);
          }
          if (!match) {
            return null;
          }

          return buffer.slice(0, match.index) + match?.[0];
        },
      }),
      // your other options
      
      // maxTokens: 2048,
      // messages: convertToCoreMessages(messages),
      // model: openai('gpt-4o'),
      // system: system,
    });

```

## Keyboard Shortcuts

<KeyTable>
  <KeyTableItem hotkey="Space">
    Open AI menu in empty block (cursor mode)
  </KeyTableItem>
  <KeyTableItem hotkey="Cmd + J">
    Open AI menu (cursor or selection mode)
  </KeyTableItem>
  <KeyTableItem hotkey="Escape">Close AI menu</KeyTableItem>
</KeyTable>

## Examples

### Plate UI

Refer to the preview above.

### Plate Plus

<ComponentPreviewPro name="ai-pro" />

## Plugins

### `AIPlugin`

Extends the editor with AI transforms.

### `AIChatPlugin`

This plugin is experimental.

Enables chat operations and streaming text generation in the editor.

<API name="AIChatPlugin">
<APIOptions>
  <APIItem name="aiEditor" type="SlateEditor | null">
    The Editor used to generate the AI response.
  </APIItem>
  <APIItem name="chat" type="Partial<UseChatHelpers>">
    Chat helpers returned by [useChat](https://sdk.vercel.ai/docs/reference/ai-sdk-ui/use-chat).
  </APIItem>
  <APIItem name="mode" type="'chat' | 'insert'" optional>
    Specifies how assistant messages are handled:
    - `'chat'`: Shows preview with accept/reject options
    - `'insert'`: Directly inserts content into editor
    - **Default:** `'chat'`
  </APIItem>
  <APIItem name="open" type="boolean" optional>
    Whether the AI chat is open.
    - **Default:** `false`
  </APIItem>
  <APIItem name="streaming" type="boolean" optional>
    Whether the AI response is currently streaming. Cursor mode only.
    - **Default:** `false`
  </APIItem>
  <APIItem name="promptTemplate" type="(props: EditorPromptParams) => string" optional>
    Template for generating prompts. Supports placeholders:
    - `{block}`: Markdown of blocks in selection
    - `{editor}`: Markdown of entire editor content
    - `{selection}`: Markdown of current selection
    - `{prompt}`: Actual user prompt
    - **Default:** `'{prompt}'`
  </APIItem>
  <APIItem name="systemTemplate" type="(props: EditorPromptParams) => string | void" optional>
    Template for system messages. Supports same placeholders as `promptTemplate`.
  </APIItem>
    <APIItem name="_blockChunks" type="string">
    Used internally for streamInsertChunk.
  </APIItem>
  <APIItem name="_blockPath" type="Path | null">
    Used internally for tracking block path.
  </APIItem>
</APIOptions>
</API>

## API

### `api.aiChat.accept`

Accepts the current AI suggestion:
- Removes AI marks from the content
- Hides the AI chat interface
- Focuses the editor

### `api.aiChat.insertBelow`

Inserts AI content below the current block.

Handles both block selection and normal selection modes:
- In block selection: Inserts after the last selected block, applying formatting from the last block
- In normal selection: Inserts after the current block, applying formatting from the current block

<API name="insertBelow">
<APIParameters>
  <APIItem name="sourceEditor" type="PlateEditor">
    Editor containing the content to insert.
  </APIItem>
  <APIItem name="options" type="object" optional>
    Options for insertion.
  </APIItem>
</APIParameters>

<APIOptions type="object">
  <APIItem name="format" type="'all' | 'none' | 'single'" optional>
    Format to apply:
    - `'all'`: Apply formatting to all blocks
    - `'none'`: Insert without formatting
    - `'single'`: Apply formatting only to first block
    - **Default:** `'single'`
  </APIItem>
</APIOptions>
</API>

### `api.aiChat.replaceSelection`

Replaces the current selection with AI content.

Handles different selection modes:
- Single block selection: Replaces the selected block, applying its formatting to inserted content based on format option
- Multiple block selection: Replaces all selected blocks
  - With `format: 'none'` or `'single'`: Preserves original formatting
  - With `format: 'all'`: Applies first block's formatting to all content
- Normal selection: Replaces the current selection while maintaining surrounding context

<API name="replaceSelection">
<APIParameters>
  <APIItem name="sourceEditor" type="PlateEditor">
    Editor containing the content to replace with.
  </APIItem>
  <APIItem name="options" type="object" optional>
    Options for replacement.
  </APIItem>
</APIParameters>

<APIOptions type="object">
  <APIItem name="format" type="'all' | 'none' | 'single'" optional>
    Format to apply:
    - `'all'`: Apply formatting to all blocks
    - `'none'`: Insert without formatting
    - `'single'`: Apply formatting only to first block
    - **Default:** `'single'`
  </APIItem>
</APIOptions>
</API>

### `api.aiChat.reset`

Resets the chat state:
- Stops any ongoing generation
- Clears chat messages
- Removes all AI nodes from the editor

### `api.aiChat.node`

Gets the AI chat node entry.

<API name="node">
<APIParameters>
  <APIItem name="options" type="EditorNodesOptions & { anchor?: boolean }" optional>
    Options for finding the node.
    - `anchor`: When true, finds nodes with type matching the plugin type
    - When false (default), finds nodes with the `ai` property
  </APIItem>
</APIParameters>
<APIReturns type="NodeEntry | undefined">
  The found node entry or undefined if not found.
</APIReturns>
</API>

### `api.aiChat.reload`

Reloads the current AI chat:
- In insert mode: Undoes previous AI changes
- Reloads the chat with the current system prompt

### `api.aiChat.show`

Shows the AI chat interface:
- Resets the chat state
- Clears messages
- Sets the open state to true

### `api.aiChat.hide`

Hides the AI chat interface:
- Resets the chat state
- Sets the open state to false
- Focuses the editor
- Removes the AI anchor

### `api.aiChat.stop`

Stops the current AI generation:
- Sets streaming state to false
- Calls the chat stop function

### `api.aiChat.submit`

Submits a prompt to generate AI content.

<API name="submit">
<APIOptions type="SubmitOptions">
  <APIItem name="mode" type="'chat' | 'insert'" optional>
    Mode to use. In insert mode, undoes previous AI changes before submitting.
    - **Default:** `'chat'` for selection, `'insert'` otherwise
  </APIItem>
  <APIItem name="prompt" type="string" optional>
    Custom prompt.
    - **Default:** Uses chat input if not provided
  </APIItem>
  <APIItem name="system" type="string" optional>
    Custom system message.
  </APIItem>
</APIOptions>
</API>

## Transforms

### `tf.aiChat.removeAnchor`

Removes the AI chat anchor node.

<API name="removeAnchor">
<APIParameters>
  <APIItem name="options" type="EditorNodesOptions" optional>
    Options for finding nodes to remove.
  </APIItem>
</APIParameters>
</API>

### `tf.ai.insertNodes`

Inserts AI-generated nodes with the AI mark.

<API name="tf.ai.insertNodes">
<APIParameters>
  <APIItem name="nodes" type="Descendant[]">
    Nodes to insert with AI mark.
  </APIItem>
  <APIItem name="options" type="InsertNodesOptions" optional>
    Options for inserting nodes.
  </APIItem>
</APIParameters>

<APIOptions type="InsertNodesOptions">
  <APIItem name="target" type="Path" optional>
    Target path.
    - **Default:** Current selection
  </APIItem>
</APIOptions>
</API>

### `tf.ai.removeMarks`

Removes AI marks from nodes in the specified location.

<API name="tf.ai.removeMarks">
<APIOptions type="RemoveMarksOptions">
  <APIItem name="at" type="Location" optional>
    Location to remove marks from.
    - **Default:** Entire document
  </APIItem>
</APIOptions>
</API>

### `tf.ai.removeNodes`

Removes nodes that have the AI mark.

<API name="tf.ai.removeNodes">
<APIOptions type="RemoveNodesOptions">
  <APIItem name="at" type="Path" optional>
    Path to remove nodes from.
    - **Default:** Entire document
  </APIItem>
</APIOptions>
</API>

### `tf.ai.undo`

Special undo operation for AI changes:
- Undoes the last operation if it was AI-generated
- Removes the redo stack entry to prevent redoing AI operations

### `useAIChatEditor`

A hook that registers an editor in the AI chat plugin, and deserializes markdown content with block-level memoization.

<API name="useAIChatEditor">
<APIParameters>
  <APIItem name="content" type="string">
    The markdown content to deserialize into the editor.
  </APIItem>
  <APIItem name="options" type="object" optional>
    <APISubList>
      <APISubListItem parent="options" name="memoize" type="boolean" optional>
        Enable block-level memoization with `_memo` property.
        - **Default:** `true`
      </APISubListItem>
      <APISubListItem parent="options" name="parser" type="ParseMarkdownBlocksOptions" optional>
        Options for the markdown token parser. Can filter out specific token types.
      </APISubListItem>
      <APISubListItem parent="options" name="processor" type="(processor: Processor) => Processor" optional>
        Function to customize the markdown processor.
      </APISubListItem>
    </APISubList>
  </APIItem>
</APIParameters>

```tsx
const AIChatEditor = ({ content }: { content: string }) => {
  const aiEditor = usePlateEditor({
    plugins: [
      // Your editor plugins
      MarkdownPlugin,
      // etc...
    ],
  });

  useAIChatEditor(aiEditor, content, {
    // Optional markdown parser options
    parser: {
      exclude: ['space'],
    },
  });

  return <Editor editor={aiEditor} />;
};
```
</API>

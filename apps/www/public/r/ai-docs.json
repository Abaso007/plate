{
  "$schema": "https://ui.shadcn.com/schema/registry-item.json",
  "name": "ai-docs",
  "type": "registry:file",
  "title": "AI",
  "description": "Documentation for AI",
  "files": [
    {
      "path": "../../docs/ai.mdx",
      "content": "---\ntitle: AI\ndocs:\n  - route: https://pro.platejs.org/docs/examples/ai\n    title: AI\n---\n\n<ComponentPreview name=\"ai-demo\" />\n\n<PackageInfo>\n\n## Features\n\n- Combobox menu with predefined commands:\n  - Generate: continue writing, add summary, explain\n  - Edit: improve writing, emojify, make it longer or shorter, fix spelling & grammar, simplify language\n- Three trigger modes:\n  - Cursor mode: trigger at block end\n  - Selection mode: trigger with selected text\n  - Block selection mode: trigger with selected blocks\n- Streaming responses in preview or direct editor insertion\n- Markdown support\n- Built-in support for Vercel AI SDK chat API\n\n</PackageInfo>\n\n## Installation\n\n```bash\nnpm install @udecode/plate-ai @udecode/plate-selection @udecode/plate-markdown @udecode/plate-basic-nodes\n```\n\n## Usage\n\n### Plugins\n\n```tsx\nimport { AIChatPlugin, AIPlugin } from '@udecode/plate-ai/react';\nimport {\n  BaseBoldPlugin,\n  BaseCodePlugin,\n  BaseItalicPlugin,\n  BaseStrikethroughPlugin,\n  BaseUnderlinePlugin,\n  BaseHorizontalRulePlugin, BaseHeadingPlugin, BaseBlockquotePlugin\n} from '@udecode/plate-basic-nodes';\nimport {\n  BaseCodeBlockPlugin,\n  BaseCodeLinePlugin,\n  BaseCodeSyntaxPlugin,\n} from '@udecode/plate-code-block';\nimport { createSlateEditor, KEYS } from '@udecode/plate';\nimport { BaseListPlugin } from '@udecode/plate-list';\nimport { BaseLinkPlugin } from '@udecode/plate-link';\nimport { MarkdownPlugin } from '@udecode/plate-markdown';\n```\n\n```tsx\nexport const createAIEditor = () => {\n  const editor = createSlateEditor({\n    id: 'ai',\n    plugins: [\n      BaseBlockquotePlugin,\n      BaseBoldPlugin,\n      BaseCodeBlockPlugin,\n      BaseCodeLinePlugin,\n      BaseCodePlugin,\n      BaseCodeSyntaxPlugin,\n      BaseItalicPlugin,\n      BaseStrikethroughPlugin,\n      BaseUnderlinePlugin,\n      BaseHeadingPlugin,\n      BaseHorizontalRulePlugin,\n      BaseLinkPlugin,\n      BaseListPlugin.extend({\n        inject: {\n          targetPlugins: [\n            KEYS.p,\n            ...KEYS.heading,\n            KEYS.blockquote,\n            KEYS.codeBlock,\n          ],\n        },\n        options: {\n          listStyleTypes: {\n            todo: {\n              liComponent: TodoLiStatic,\n              markerComponent: TodoMarkerStatic,\n              type: 'todo',\n            },\n          },\n        },\n      }),\n      MarkdownPlugin.configure({\n        options: {\n          remarkPlugins: [remarkMath, remarkGfm, remarkMdx],\n        },\n      }),\n    ],\n  });\n\n\n  return editor;\n};\n\nconst systemCommon = `\\\nYou are an advanced AI-powered note-taking assistant, designed to enhance productivity and creativity in note management.\nRespond directly to user prompts with clear, concise, and relevant content. Maintain a neutral, helpful tone.\n\nRules:\n- <Document> is the entire note the user is working on.\n- <Reminder> is a reminder of how you should reply to INSTRUCTIONS. It does not apply to questions.\n- Anything else is the user prompt.\n- Your response should be tailored to the user's prompt, providing precise assistance to optimize note management.\n- For INSTRUCTIONS: Follow the <Reminder> exactly. Provide ONLY the content to be inserted or replaced. No explanations or comments.\n- For QUESTIONS: Provide a helpful and concise answer. You may include brief explanations if necessary.\n- CRITICAL: Distinguish between INSTRUCTIONS and QUESTIONS. Instructions typically ask you to modify or add content. Questions ask for information or clarification.\n`;\n\nconst systemDefault = `\\\n${systemCommon}\n- <Block> is the current block of text the user is working on.\n- Ensure your output can seamlessly fit into the existing <Block> structure.\n- CRITICAL: Provide only a single block of text. DO NOT create multiple paragraphs or separate blocks.\n<Block>\n{block}\n</Block>\n`;\n\nconst systemSelecting = `\\\n${systemCommon}\n- <Block> is the block of text containing the user's selection, providing context.\n- Ensure your output can seamlessly fit into the existing <Block> structure.\n- <Selection> is the specific text the user has selected in the block and wants to modify or ask about.\n- Consider the context provided by <Block>, but only modify <Selection>. Your response should be a direct replacement for <Selection>.\n<Block>\n{block}\n</Block>\n<Selection>\n{selection}\n</Selection>\n`;\n\nconst systemBlockSelecting = `\\\n${systemCommon}\n- <Selection> represents the full blocks of text the user has selected and wants to modify or ask about.\n- Your response should be a direct replacement for the entire <Selection>.\n- Maintain the overall structure and formatting of the selected blocks, unless explicitly instructed otherwise.\n- CRITICAL: Provide only the content to replace <Selection>. Do not add additional blocks or change the block structure unless specifically requested.\n<Selection>\n{block}\n</Selection>\n`;\n\nconst userDefault = `<Reminder>\nCRITICAL: DO NOT use block formatting. You can only use inline formatting.\nCRITICAL: DO NOT start new lines or paragraphs.\nNEVER write <Block>.\n</Reminder>\n{prompt}`;\n\nconst userSelecting = `<Reminder>\nIf this is a question, provide a helpful and concise answer about <Selection>.\nIf this is an instruction, provide ONLY the text to replace <Selection>. No explanations.\nEnsure it fits seamlessly within <Block>. If <Block> is empty, write ONE random sentence.\nNEVER write <Block> or <Selection>.\n</Reminder>\n{prompt} about <Selection>`;\n\nconst userBlockSelecting = `<Reminder>\nIf this is a question, provide a helpful and concise answer about <Selection>.\nIf this is an instruction, provide ONLY the content to replace the entire <Selection>. No explanations.\nMaintain the overall structure unless instructed otherwise.\nNEVER write <Block> or <Selection>.\n</Reminder>\n{prompt} about <Selection>`;\n\nexport const PROMPT_TEMPLATES = {\n  systemBlockSelecting,\n  systemDefault,\n  systemSelecting,\n  userBlockSelecting,\n  userDefault,\n  userSelecting,\n};\n\nconst plugins = [\n  // ...otherPlugins,\n  MarkdownPlugin.configure({\n    options: {\n      remarkPlugins: [remarkMath, remarkGfm, remarkMdx],\n    },\n  }),\n  AIPlugin,\n  AIChatPlugin.configure({\n    options: {\n      createAIEditor,\n      promptTemplate: ({ isBlockSelecting, isSelecting }) => {\n        return isBlockSelecting\n          ? PROMPT_TEMPLATES.userBlockSelecting\n          : isSelecting\n            ? PROMPT_TEMPLATES.userSelecting\n            : PROMPT_TEMPLATES.userDefault;\n      },\n      systemTemplate: ({ isBlockSelecting, isSelecting }) => {\n        return isBlockSelecting\n          ? PROMPT_TEMPLATES.systemBlockSelecting\n          : isSelecting\n            ? PROMPT_TEMPLATES.systemSelecting\n            : PROMPT_TEMPLATES.systemDefault;\n      },\n    },\n    render: { afterEditable: () => <AIMenu /> },\n  }),\n];\n```\n\n- [AIMenu](/docs/components/ai-menu)\n\n### AI SDK\n\nThis plugin is depending on the [ai](https://npmjs.com/package/ai) package:\n\n- Setup a [route handler](https://sdk.vercel.ai/docs/installation/nextjs-app-router#create-a-route-handler) using [streamText](https://sdk.vercel.ai/docs/ai-sdk-core/generating-text#streamtext).\n- Wire up [useChat](https://sdk.vercel.ai/docs/reference/ai-sdk-ui/use-chat) in your [AI menu](/docs/components/ai-menu) component.\n\n\n### Convert the chunk into a plate nodes.\nBy default, AI responses are streamed to the Plate editor in a chunk-by-chunk manner.\n\nHowever, this chunking approach can cause issues when handling complex nodes like tables and code blocks. If chunks are split too frequently, it can lead to performance problems as these heavy nodes are repeatedly replaced.\n\nTo solve this issue, it's recommended to use the `experimental_transform` parameter with the `smoothStream` function in the `streamText` function to optimize the chunk transmission.\n\nThe chunking function below implements the following default behavior: it uses line-based chunking for tables, math, links, and code blocks, while using word-based chunking for all other content.\n\n```ts\n    const result = streamText({\n      experimental_transform: smoothStream({\n        chunking: (buffer) => {\n          // Check for code block markers\n          if (/```[^\\s]+/.test(buffer)) {\n            isInCodeBlock = true\n          }else if(isInCodeBlock && buffer.includes('```') ) {\n            isInCodeBlock = false\n          }\n          // test case: should not deserialize link with markdown syntax\n          if (buffer.includes('http')) {\n            isInLink = true;\n          } else if (buffer.includes('https')) {\n            isInLink = true;\n          } else if (buffer.includes('\\n') && isInLink) {\n            isInLink = false;\n          }\n          if (buffer.includes('*') || buffer.includes('-')) {\n            isInList = true;\n          } else if (buffer.includes('\\n') && isInList) {\n            isInList = false;\n          }\n          // Simple table detection: enter on |, exit on double newline\n          if (!isInTable && buffer.includes('|')) {\n            isInTable = true;\n          } else if (isInTable && buffer.includes('\\n\\n')) {\n            isInTable = false;\n          }\n\n          // Use line chunking for code blocks and tables, word chunking otherwise\n          // Choose the appropriate chunking strategy based on content type\n          let match;\n\n          if (isInCodeBlock || isInTable || isInLink) {\n            // Use line chunking for code blocks and tables\n            match = CHUNKING_REGEXPS.line.exec(buffer);\n          } else if (isInList) {\n            // Use list chunking for lists\n            match = CHUNKING_REGEXPS.list.exec(buffer);\n          } else {\n            // Use word chunking for regular text\n            match = CHUNKING_REGEXPS.word.exec(buffer);\n          }\n          if (!match) {\n            return null;\n          }\n\n          return buffer.slice(0, match.index) + match?.[0];\n        },\n      }),\n      // your other options\n      \n      // maxTokens: 2048,\n      // messages: convertToCoreMessages(messages),\n      // model: openai('gpt-4o'),\n      // system: system,\n    });\n\n```\n\n## Keyboard Shortcuts\n\n<KeyTable>\n  <KeyTableItem hotkey=\"Space\">\n    Open AI menu in empty block (cursor mode)\n  </KeyTableItem>\n  <KeyTableItem hotkey=\"Cmd + J\">\n    Open AI menu (cursor or selection mode)\n  </KeyTableItem>\n  <KeyTableItem hotkey=\"Escape\">Close AI menu</KeyTableItem>\n</KeyTable>\n\n## Examples\n\n### Plate UI\n\nRefer to the preview above.\n\n### Plate Plus\n\n<ComponentPreviewPro name=\"ai-pro\" />\n\n## Plugins\n\n### `AIPlugin`\n\nExtends the editor with AI transforms.\n\n### `AIChatPlugin`\n\nThis plugin is experimental.\n\nEnables chat operations and streaming text generation in the editor.\n\n<API name=\"AIChatPlugin\">\n<APIOptions>\n  <APIItem name=\"aiEditor\" type=\"SlateEditor | null\">\n    The Editor used to generate the AI response.\n  </APIItem>\n  <APIItem name=\"chat\" type=\"Partial<UseChatHelpers>\">\n    Chat helpers returned by [useChat](https://sdk.vercel.ai/docs/reference/ai-sdk-ui/use-chat).\n  </APIItem>\n  <APIItem name=\"mode\" type=\"'chat' | 'insert'\" optional>\n    Specifies how assistant messages are handled:\n    - `'chat'`: Shows preview with accept/reject options\n    - `'insert'`: Directly inserts content into editor\n    - **Default:** `'chat'`\n  </APIItem>\n  <APIItem name=\"open\" type=\"boolean\" optional>\n    Whether the AI chat is open.\n    - **Default:** `false`\n  </APIItem>\n  <APIItem name=\"streaming\" type=\"boolean\" optional>\n    Whether the AI response is currently streaming. Cursor mode only.\n    - **Default:** `false`\n  </APIItem>\n  <APIItem name=\"promptTemplate\" type=\"(props: EditorPromptParams) => string\" optional>\n    Template for generating prompts. Supports placeholders:\n    - `{block}`: Markdown of blocks in selection\n    - `{editor}`: Markdown of entire editor content\n    - `{selection}`: Markdown of current selection\n    - `{prompt}`: Actual user prompt\n    - **Default:** `'{prompt}'`\n  </APIItem>\n  <APIItem name=\"systemTemplate\" type=\"(props: EditorPromptParams) => string | void\" optional>\n    Template for system messages. Supports same placeholders as `promptTemplate`.\n  </APIItem>\n    <APIItem name=\"_blockChunks\" type=\"string\">\n    Used internally for streamInsertChunk.\n  </APIItem>\n  <APIItem name=\"_blockPath\" type=\"Path | null\">\n    Used internally for tracking block path.\n  </APIItem>\n</APIOptions>\n</API>\n\n## API\n\n### `api.aiChat.accept`\n\nAccepts the current AI suggestion:\n- Removes AI marks from the content\n- Hides the AI chat interface\n- Focuses the editor\n\n### `api.aiChat.insertBelow`\n\nInserts AI content below the current block.\n\nHandles both block selection and normal selection modes:\n- In block selection: Inserts after the last selected block, applying formatting from the last block\n- In normal selection: Inserts after the current block, applying formatting from the current block\n\n<API name=\"insertBelow\">\n<APIParameters>\n  <APIItem name=\"sourceEditor\" type=\"PlateEditor\">\n    Editor containing the content to insert.\n  </APIItem>\n  <APIItem name=\"options\" type=\"object\" optional>\n    Options for insertion.\n  </APIItem>\n</APIParameters>\n\n<APIOptions type=\"object\">\n  <APIItem name=\"format\" type=\"'all' | 'none' | 'single'\" optional>\n    Format to apply:\n    - `'all'`: Apply formatting to all blocks\n    - `'none'`: Insert without formatting\n    - `'single'`: Apply formatting only to first block\n    - **Default:** `'single'`\n  </APIItem>\n</APIOptions>\n</API>\n\n### `api.aiChat.replaceSelection`\n\nReplaces the current selection with AI content.\n\nHandles different selection modes:\n- Single block selection: Replaces the selected block, applying its formatting to inserted content based on format option\n- Multiple block selection: Replaces all selected blocks\n  - With `format: 'none'` or `'single'`: Preserves original formatting\n  - With `format: 'all'`: Applies first block's formatting to all content\n- Normal selection: Replaces the current selection while maintaining surrounding context\n\n<API name=\"replaceSelection\">\n<APIParameters>\n  <APIItem name=\"sourceEditor\" type=\"PlateEditor\">\n    Editor containing the content to replace with.\n  </APIItem>\n  <APIItem name=\"options\" type=\"object\" optional>\n    Options for replacement.\n  </APIItem>\n</APIParameters>\n\n<APIOptions type=\"object\">\n  <APIItem name=\"format\" type=\"'all' | 'none' | 'single'\" optional>\n    Format to apply:\n    - `'all'`: Apply formatting to all blocks\n    - `'none'`: Insert without formatting\n    - `'single'`: Apply formatting only to first block\n    - **Default:** `'single'`\n  </APIItem>\n</APIOptions>\n</API>\n\n### `api.aiChat.reset`\n\nResets the chat state:\n- Stops any ongoing generation\n- Clears chat messages\n- Removes all AI nodes from the editor\n\n### `api.aiChat.node`\n\nGets the AI chat node entry.\n\n<API name=\"node\">\n<APIParameters>\n  <APIItem name=\"options\" type=\"EditorNodesOptions & { anchor?: boolean }\" optional>\n    Options for finding the node.\n    - `anchor`: When true, finds nodes with type matching the plugin type\n    - When false (default), finds nodes with the `ai` property\n  </APIItem>\n</APIParameters>\n<APIReturns type=\"NodeEntry | undefined\">\n  The found node entry or undefined if not found.\n</APIReturns>\n</API>\n\n### `api.aiChat.reload`\n\nReloads the current AI chat:\n- In insert mode: Undoes previous AI changes\n- Reloads the chat with the current system prompt\n\n### `api.aiChat.show`\n\nShows the AI chat interface:\n- Resets the chat state\n- Clears messages\n- Sets the open state to true\n\n### `api.aiChat.hide`\n\nHides the AI chat interface:\n- Resets the chat state\n- Sets the open state to false\n- Focuses the editor\n- Removes the AI anchor\n\n### `api.aiChat.stop`\n\nStops the current AI generation:\n- Sets streaming state to false\n- Calls the chat stop function\n\n### `api.aiChat.submit`\n\nSubmits a prompt to generate AI content.\n\n<API name=\"submit\">\n<APIOptions type=\"SubmitOptions\">\n  <APIItem name=\"mode\" type=\"'chat' | 'insert'\" optional>\n    Mode to use. In insert mode, undoes previous AI changes before submitting.\n    - **Default:** `'chat'` for selection, `'insert'` otherwise\n  </APIItem>\n  <APIItem name=\"prompt\" type=\"string\" optional>\n    Custom prompt.\n    - **Default:** Uses chat input if not provided\n  </APIItem>\n  <APIItem name=\"system\" type=\"string\" optional>\n    Custom system message.\n  </APIItem>\n</APIOptions>\n</API>\n\n## Transforms\n\n### `tf.aiChat.removeAnchor`\n\nRemoves the AI chat anchor node.\n\n<API name=\"removeAnchor\">\n<APIParameters>\n  <APIItem name=\"options\" type=\"EditorNodesOptions\" optional>\n    Options for finding nodes to remove.\n  </APIItem>\n</APIParameters>\n</API>\n\n### `tf.ai.insertNodes`\n\nInserts AI-generated nodes with the AI mark.\n\n<API name=\"tf.ai.insertNodes\">\n<APIParameters>\n  <APIItem name=\"nodes\" type=\"Descendant[]\">\n    Nodes to insert with AI mark.\n  </APIItem>\n  <APIItem name=\"options\" type=\"InsertNodesOptions\" optional>\n    Options for inserting nodes.\n  </APIItem>\n</APIParameters>\n\n<APIOptions type=\"InsertNodesOptions\">\n  <APIItem name=\"target\" type=\"Path\" optional>\n    Target path.\n    - **Default:** Current selection\n  </APIItem>\n</APIOptions>\n</API>\n\n### `tf.ai.removeMarks`\n\nRemoves AI marks from nodes in the specified location.\n\n<API name=\"tf.ai.removeMarks\">\n<APIOptions type=\"RemoveMarksOptions\">\n  <APIItem name=\"at\" type=\"Location\" optional>\n    Location to remove marks from.\n    - **Default:** Entire document\n  </APIItem>\n</APIOptions>\n</API>\n\n### `tf.ai.removeNodes`\n\nRemoves nodes that have the AI mark.\n\n<API name=\"tf.ai.removeNodes\">\n<APIOptions type=\"RemoveNodesOptions\">\n  <APIItem name=\"at\" type=\"Path\" optional>\n    Path to remove nodes from.\n    - **Default:** Entire document\n  </APIItem>\n</APIOptions>\n</API>\n\n### `tf.ai.undo`\n\nSpecial undo operation for AI changes:\n- Undoes the last operation if it was AI-generated\n- Removes the redo stack entry to prevent redoing AI operations\n\n### `useAIChatEditor`\n\nA hook that registers an editor in the AI chat plugin, and deserializes markdown content with block-level memoization.\n\n<API name=\"useAIChatEditor\">\n<APIParameters>\n  <APIItem name=\"content\" type=\"string\">\n    The markdown content to deserialize into the editor.\n  </APIItem>\n  <APIItem name=\"options\" type=\"object\" optional>\n    <APISubList>\n      <APISubListItem parent=\"options\" name=\"memoize\" type=\"boolean\" optional>\n        Enable block-level memoization with `_memo` property.\n        - **Default:** `true`\n      </APISubListItem>\n      <APISubListItem parent=\"options\" name=\"parser\" type=\"ParseMarkdownBlocksOptions\" optional>\n        Options for the markdown token parser. Can filter out specific token types.\n      </APISubListItem>\n      <APISubListItem parent=\"options\" name=\"processor\" type=\"(processor: Processor) => Processor\" optional>\n        Function to customize the markdown processor.\n      </APISubListItem>\n    </APISubList>\n  </APIItem>\n</APIParameters>\n\n```tsx\nconst AIChatEditor = ({ content }: { content: string }) => {\n  const aiEditor = usePlateEditor({\n    plugins: [\n      // Your editor plugins\n      MarkdownPlugin,\n      // etc...\n    ],\n  });\n\n  useAIChatEditor(aiEditor, content, {\n    // Optional markdown parser options\n    parser: {\n      exclude: ['space'],\n    },\n  });\n\n  return <Editor editor={aiEditor} />;\n};\n```\n</API>\n",
      "type": "registry:file",
      "target": "content/docs/plate/plugins/ai.mdx"
    }
  ]
}